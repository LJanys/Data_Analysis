[
["problem-set-2.html", "Chapter 11 Problem Set 2 11.1 Implementing the F-statistic 11.2 Simulation Study 11.3 Simulation study: Violating model assumptions", " Chapter 11 Problem Set 2 The model used in the simulation has the following structure: \\[x_{i1}=1, x_{i2},x_{i3} \\sim \\mathcal{N}(0,\\Sigma)\\] \\[y_{i}=\\mathbf{x}_i&#39;\\boldsymbol{\\beta}+\\varepsilon_i\\] Assume througout that \\(n=10000\\). The aim of this problem set is to implement the F-test for joint hypothesis testing and to compare the performance of the F-test if the model assumptions upon which the test statistics are derived, are violated. 11.1 Implementing the F-statistic Assume initially that \\(\\boldsymbol{\\beta}=\\left(\\begin{matrix}1&amp;0&amp;0\\end{matrix}\\right)\\) and that \\(\\varepsilon_i\\sim\\mathcal{N}(0,10)\\). Calculate the OLS estimator \\(\\hat{\\boldsymbol{\\beta}}\\), implement the F-Statistic and compare the value of the F-Statistic with the relevant quantile from the F-distribution. Does the global Null hold? k1&lt;-rep(1, N)##generating the constant. # We will use the command mvrnorm to draw a matrix of variables mu &lt;- rep(0,M) ####beta vector### het&lt;-0###if equal to one: simulate a heteroskedastic model beta.vec&lt;-c(1,0,0)# ###We specify the correlation among the variables ###if there is correlation, right now no correlation####################### #Sigma &lt;- matrix(1.4, nrow=M, ncol=M) + diag(M)*.3 Sigma &lt;- matrix(0, nrow=M, ncol=M) + diag(M) ###We draw normally distributed variables from a joint normal distribution### rawvars &lt;- mvrnorm(N, mu=mu, Sigma=Sigma) ###Let&#39;s see if they look normally distributed### plot(density(rawvars[,1])) lines(density(rawvars[,2]),col=&quot;red&quot;) mean(rawvars[,1]);sd(rawvars[,1]);mean(rawvars[,2]);sd(rawvars[,2]) ##Display the correlation matrix### cov(rawvars);cor(rawvars) Sigma X &lt;- cbind(k1,rawvars) if(het==1) { eps &lt;-X[,2]^2*rnorm(N, 0,10) }else{ eps &lt;-rnorm(N, 0,10)} ###generate the model#### y &lt;- X %*% beta.vec + eps ##Solving for beta hat### beta.hat &lt;- solve(t(X) %*% X) %*% t(X) %*% y beta.hat # ####Now, let&#39;s calculate the value for the t-test#### xx&lt;-dim(X) length.x&lt;-xx[2] y.hat&lt;- X %*% beta.hat eps.hat&lt;-y-X %*% beta.hat se&lt;-(t(eps.hat)%*%(eps.hat))/(N-length.x)###Calculate the estimate for the error variance cov&lt;-se[1]*solve(t(X) %*% X)###Calculate the Covariance matrix d1&lt;-sqrt(diag(cov))###The standard errors for the parameters ####Below we calculate the f-statistic as the ratio of the variances### f&lt;-(sum((y.hat-mean(y))^2)/(M+1-1))/(sum((y-y.hat)^2)/(N-M+1)) f.crit&lt;-qf(.95, df1=M, df2=N-M) result&lt;-f&gt;f.crit 11.2 Simulation Study Write the code above into a function that returns a logical expression whether the Null was rejected. Repeat this calculation 1000 times and record your results in a vector. What is the expected number of rejected hypotheses in this scenario? Summarize and discuss your results. simu_data&lt;-function(N,Sigma,het=0,beta.vec){ k1&lt;-rep(1, N)##generating the constant. # We will use the command mvrnorm to draw a matrix of variables mu &lt;- rep(0,M) ###We specify the correlation among the variables #Sigma &lt;- matrix(1.4, nrow=M, ncol=M) + diag(M)*.3 Sigma &lt;- matrix(0, nrow=M, ncol=M) + diag(M) ###We draw normally distributed variables from a joint normal distribution### rawvars &lt;- mvrnorm(N, mu=mu, Sigma=Sigma) mean(rawvars[,1]);sd(rawvars[,1]);mean(rawvars[,2]);sd(rawvars[,2]) ##Display the correlation matrix### cov(rawvars);cor(rawvars) Sigma X &lt;- cbind(k1,rawvars) if(het==1) { eps &lt;-X[,2]*rnorm(N, 0,10) }else{ eps &lt;-rnorm(N, 0,10)} ###generate the model#### y &lt;- X %*% beta.vec + eps ##Solving for beta hat### beta.hat &lt;- solve(t(X) %*% X) %*% t(X) %*% y beta.hat ####Now, let&#39;s calculate the value for the t-test#### xx&lt;-dim(X) length.x&lt;-xx[2] y.hat&lt;- X %*% beta.hat eps.hat&lt;-y-X %*% beta.hat se&lt;-(t(eps.hat)%*%(eps.hat))/(N-length.x) cov&lt;-se[1]*solve(t(X) %*% X) d1&lt;-sqrt(diag(cov)) f&lt;-(sum((y.hat-mean(y))^2)/(M+1-1))/(sum((y-y.hat)^2)/(N-M+1)) f.crit&lt;-qf(.95, df1=M, df2=N-M) result&lt;-f&gt;f.crit return(result) } ###Make this into a function################################################################ beta.vec&lt;-c(1,0,0) simu_data(N,Sigma,het=0,beta.vec) ###make a vector that records the decision#################### result&lt;-c() reps&lt;-100 for(i in 1:reps) { set.seed(i) result[i]=simu_data(N,Sigma,het=0,beta.vec) } sum(result) 11.3 Simulation study: Violating model assumptions Re-write the function above to include the option for simulating heteroskedasticity. Come up with a suitable way to simulate heteroskedasticity in the model and run the simulation above again. What is your expectation? result_het&lt;-c() reps&lt;-100 for(i in 1:reps) { set.seed(i) result_het[i]=simu_data(N,Sigma,het=1,beta.vec) } sum(result_het) "]
]
